---
title: "NYC LL84 ML"
author: "Eden Axelrad"
date: "7/17/2022"
output: html_document
---

## SECTION 1: Introduction and Overview

- Data retrieved from NYC Open Data as part of Local Law 84 (LL84)
- Data described as Data and metrics on water and energy consumption in privately owned buildings over 25,000 ft2 and in City-owned buildings over 10,000 ft2.
- R script used to retrieve, wrangle, and clean the data frame used in this main report can be found here


## SECTION 2: Setup

In this section we set up the initial data set

```{r packages, echo=FALSE, warning=FALSE, message=FALSE}

# Load required packages
if (!require(tidyverse)) install.packages('tidyverse')
if (!require(caret)) install.packages('caret')
if (!require(rpart)) install.packages('rpart')
if (!require(glmnet)) install.packages('glmnet')
if (!require(scales)) install.packages('scales')
if (!require(knitr)) install.packages('knitr')

library(tidyverse)
library(caret)
library(rpart)
library(glmnet)

```

```{r setup, warning=FALSE}

# Load the cleaned up data for reporting years 2016 through 2019
NYC_LL84 <- read.csv("Data/NYC_LL84_Clean.csv") 

# Create our test and train data for machine learning from reporting years 2016-18
NYC_LL84_ML <- NYC_LL84 %>%
  filter(year %in% c("2016", "2017", "2018")) %>%
  select(year, primary_property_type, year_built,
         number_of_buildings, energy_star_score, property_gfa, parking_gfa,
         leed_project, CDD, HDD, MeanMaxTemp, MeanMinTemp, site_eui)

# Create the validation set to be used in the very end 
NYC_LL84_Validation <- NYC_LL84 %>%
  filter(year == "2019") %>%
  select(year, primary_property_type, year_built,
         number_of_buildings, energy_star_score, property_gfa, parking_gfa,
         leed_project, CDD, HDD, MeanMaxTemp, MeanMinTemp, site_eui)

```

## SECTION 3: Methods / Analysis

This section explains the process and techniques used, including data cleaning, data exploration and visualization, insights gained, and modeling approach

### SECTION 3.1: Exploratory Analysis

```{r exploratory, warning=FALSE, message=FALSE}

# Summary of data frame
glimpse(NYC_LL84_ML)

summary(NYC_LL84_ML$site_eui)

# EUI and GHG by Property Type
NYC_LL84_ML %>%
  group_by("Property Type" = primary_property_type) %>%
  summarise("Site EUI (kBtu/sqft)" = round(mean(site_eui), 
                                           digits = 1), 
            Count = n())  %>%
  arrange(desc(Count)) %>%
  knitr::kable()

# Explore EUI 
summary(NYC_LL84_ML$site_eui)

NYC_LL84_ML %>%
  mutate(primary_property_type = fct_reorder(primary_property_type, 
                                             site_eui)) %>%
  ggplot(aes(x = primary_property_type, 
             y = site_eui, 
             fill = primary_property_type)) +
  geom_boxplot() +
  labs(x = "Primary Property Type",
       y = "Site Energy Use Intensity (kBtu/sqft)",
       title = "Site EUI by Primary Property Type") +
  theme(legend.position = "none") +
  coord_flip()

```

```{r}

# Size of building versus EUI
summary(NYC_LL84_ML$property_gfa)

NYC_LL84_ML %>%
  mutate(size_quartile = case_when(
    `property_gfa` > 113686 ~ 4,
    `property_gfa` > 63968 & `property_gfa` <= 113686 ~ 3,
    `property_gfa` > 40760 & `property_gfa` <= 63968 ~ 2,
    `property_gfa` <= 40760 ~ 1)) %>%
  group_by(size_quartile) %>%
  summarise("Site EUI (kBtu/sqft)" = round(mean(site_eui), 
                                           digits = 1),
            Count = n())  %>%
  arrange(size_quartile) %>%
  knitr::kable()

```

```{r cor, warning=FALSE}

# Look at correlation by feature for total GHG emissions 
# Examine EUI data and check for outliers\
NYC_LL84_ML %>%
  select_if(., is.numeric) %>%
  cor() %>%
  as.data.frame() %>%
  rownames_to_column(var = "Feature") %>%
  select(Feature, site_eui) %>%
  drop_na() %>%
  arrange(desc(abs(site_eui))) %>%
  knitr::kable() 

```

insert text

### SECTION 3.2: Actual Methods

insert text

```{r, warning=FALSE}

# Partition the data in to a test set with 20% and train set with 80%
# Set seed to 92 for reproducing results  
set.seed(92, sample.kind = "Rounding")
test_index <- createDataPartition(NYC_LL84_ML$site_eui, 
                                  times = 1, p = 0.2, list = FALSE)
test_set <- NYC_LL84_ML %>% slice(test_index)
train_set <- NYC_LL84_ML %>% slice(-test_index)

```

#####  Method #1: Naive Model

```{r m1}

### Method #1: Naive Model
# Start off with a naive model that uses the average rating to predict movie ratings
mu_hat <- mean(train_set$site_eui)

rmse_naive <- RMSE(pred = mu_hat,
                   obs = test_set$site_eui)

```

##### Method #2: Mean EUI by Property Type

In the field, this is a common way of improving an estimate for EUI or GHG emissions. For this reason, I wanted to include it alongside the other methods. To execute it, simply find the average EUI by property type and left join with the test set. The assumption here is that property type is an easy way to break down the data in to categories that significantly impact EUI. 

```{r m2}

### Method #2: Using average EUI by property type 

pred_eui_avg <- left_join(test_set, 
                          train_set %>%
                            group_by(primary_property_type) %>%
                            summarize(pred_avg_eui = mean(site_eui)),
                          by = "primary_property_type") %>%
  .$pred_avg_eui

rmse_eui_avg <- RMSE(pred_eui_avg, 
                     obs = test_set$site_eui, 
                     na.rm = TRUE)

```

##### Method #3: Simple Linear Regression Using ENERGY STAR Score

```{r m3}

### Method #3: Linear Regression with Energy Star Score
# Create a linear model
set.seed(92, sample.kind = "Rounding")
model_lr <- train(site_eui ~ energy_star_score, 
               data = train_set, 
               method = "lm")

model_lr

# Generate predicted Site EUI using the test set
pred_lr <- predict(model_lr, 
                newdata = test_set %>%
                  select(site_eui, energy_star_score))

# Save the model RMSE
rmse_lr <- RMSE(pred = pred_lr, 
                    obs = test_set$site_eui, 
                    na.rm = TRUE)

```

##### Method #4: Multiple Linear Regression with all variables

```{r m4, warning=FALSE}

### Method #4: Multiple Linear Regression with all variables
# Create a linear model
set.seed(92, sample.kind = "Rounding")
model_mlr <- train(site_eui ~ ., 
                   trControl = trainControl(method = "repeatedcv", repeats = 3),
                   data = train_set, 
                   method = "lm")

model_mlr

# Generate predicted Site EUI using the test set
pred_mlr <- predict(model_mlr, 
                    newdata = test_set)

# Save the model RMSE
rmse_mlr <- RMSE(pred = pred_mlr, 
                    obs = test_set$site_eui, 
                    na.rm = TRUE)

```

##### Method #5: GLM with Regularization

```{r m6, warning=FALSE}

### Method 6: glment
set.seed(92, sample.kind = "Rounding")
model_glmnet <- train(site_eui ~ ., 
                   data = train_set, 
                   trControl = trainControl(method = "cv", repeats = 3),
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = seq(.01, 1, .01)),
                   method = "glmnet")

model_glmnet

# Generate predicted Site EUI using the test set
pred_glmnet <- predict(model_glmnet, 
                      newdata = test_set)

# Save the model RMSE
rmse_glmnet <- RMSE(pred = pred_glmnet, 
                    obs = test_set$site_eui, 
                    na.rm = TRUE)

ggplot(model_glmnet, highlight = TRUE) +
  geom_text(position = position_nudge(x = .05, y = .01), 
            aes(label = ifelse(lambda == model_glmnet$bestTune[2]$lambda, 
                               round(min(model_glmnet$results$RMSE), digits = 2), ""))) +
  labs(title = "Optimal Regularization Paramter (Lambda) for GLM Model") 

```

##### Method #5: Classification and Regression Tree (CART)

```{r m5, warning=FALSE}

### Method #5: Classification and Regression Tree (CART) with 'rpart'
# Need to add CART to packages list
set.seed(92, sample.kind = "Rounding")
model_rpart <- train(site_eui ~ ., 
                     data = train_set, 
                     trControl = trainControl(method = "repeatedcv", repeats = 3),
                     method = "rpart",
                     tuneGrid = data.frame(cp = seq(.00001, .001, .0001)))

model_rpart

# Generate predicted Site EUI using the test set
pred_rpart <- predict(model_rpart, 
                      newdata = test_set)

# Save the model RMSE
rmse_rpart <- RMSE(pred = pred_rpart, 
                   obs = test_set$site_eui, 
                   na.rm = TRUE)

ggplot(model_rpart, highlight = TRUE) +
  geom_text(position = position_nudge(x = 0.0001), 
            aes(label = ifelse(cp == model_rpart$bestTune[[1]], 
                               round(min(model_rpart$results$RMSE), digits = 2), ""))) +
  labs(title = "Optimal Complexity Paramter for CART Model") 

```



### SECTION 3.3: Validation

```{r val}

# Generate predicted Site EUI using the test set
pred_validation <- predict(model_rpart, 
                      newdata = NYC_LL84_Validation)

# Save the model RMSE
rmse_validation <- RMSE(pred = pred_validation, 
                   obs = NYC_LL84_Validation$site_eui, 
                   na.rm = TRUE)

```

## SECTION 4: Results

insert text

```{r results, warning=FALSE, message=FALSE}

Results <- cbind.data.frame(Actual = test_set$site_eui, 
                            `Naive Model` = mu_hat,
                            `Property Type Averages` = pred_eui_avg,
                            `Linear Regression` = pred_lr, 
                            `Mulitple Linear Regression` = pred_mlr, 
                            `GLM Net` = pred_glmnet,
                            `CART` = pred_rpart) %>%
  pivot_longer(cols = 2:7,
               values_to = "Predicted",
               names_to = "Model") %>%
  mutate(Residual = Actual-Predicted) %>%
  select(Model, Actual, Predicted, Residual)


# Actual vs predicted by model without outliers
Results %>%
  ggplot(aes(x = Actual, y = Predicted, color = abs(Residual))) +
  geom_point(alpha = 0.8) +
  scale_color_gradient(low = "blue", high = "red") +
  geom_smooth(color = "black", size = .5) +
  coord_equal() +
  facet_wrap(~Model) +
  labs(color = "Residual",
       title = "Actual vs Predicted Values by Model")

```

```{r final table}

# This section presents the modeling results and discusses the model performance
# Final results table with test on validation set
results_tbl <- tibble(
  Method = c("Method #1", "Method #2", "Method #3", "Method #4", "Method #5", "Method #6", "Validation"),
  Model = c("Naive Model", "EUI Averages", "LR - Energy Star", 
            "Mulitple Linear Regression", "GLM Net", "CART", "CART"),
  RMSE = c(rmse_naive, rmse_eui_avg, rmse_lr, rmse_mlr, rmse_glmnet, rmse_rpart, rmse_validation)) %>%
  mutate(`RMSE Improvment` = scales::percent((RMSE-rmse_naive)/rmse_naive))

results_tbl %>%
  mutate(RMSE = round(RMSE, digits = 2)) %>%
  knitr::kable()

```

## SECTION 5: Conclusion

insert text
